{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEBePXQ8qk8m44hUVjx75z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinisilvanunes/P1PLN/blob/master/Aula_06_An%C3%A1lise_Sem%C3%A2ntica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aula 06** - Interpretação Semântica e Gramática"
      ],
      "metadata": {
        "id": "25C8I-ncPJik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compreender os conceitos de **interpretação semântica** e sua importância no Processamento de Linguagem Natural (PLN).\n",
        "- Explorar **estruturas gramaticais** e seu impacto na análise de textos.\n",
        "- Aplicar técnicas de **análise semântica** em um corpus textual.\n",
        "- Utilizar bibliotecas de PLN para **extrair significado de textos**."
      ],
      "metadata": {
        "id": "TQvk_5BQQCVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 01 - Representação do significado das palavras e frases com resdes semânticas"
      ],
      "metadata": {
        "id": "KDr-7FskReLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet') #Banco de dados para utilização do sinônimos\n",
        "nltk.download('omw-1.4') #Corpus que relaciona as palavras em diversos idiomas - tradução automática\n",
        "\n",
        "sinonimos = wordnet.synsets(\"carro\", lang=\"por\") # Método para encontrar os sinônimos da palavra indicada e o idioma\n",
        "\n",
        "print(sinonimos) # Imprimir a lista gerada\n",
        "\n",
        "for s in sinonimos:\n",
        "    print(s.lemmas()[0].name()) # Mostrar sinônimos da palavra\n",
        "    \"\"\"\n",
        "      s.lemma(): obtém a lista de memmas(formas básicas da palavra) no synset atual.\n",
        "      [0]: pega o primeiro lemma da lista.\n",
        "      .name(): obtém o nome do lemma (o sinonimo em si)\n",
        "      print(): imprime o sinonimo na tela\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EefwN35dRdOk",
        "outputId": "b18440e6-8706-43ae-b661-ff7b9b0b9ab3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('beach_wagon.n.01'), Synset('car.n.01'), Synset('car.n.02'), Synset('cart.n.01')]\n",
            "beach_wagon\n",
            "car\n",
            "car\n",
            "cart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 2 - Representação do significado das palavras e frases por vetores (embeddings)."
      ],
      "metadata": {
        "id": "yXfiQSEcURZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qt-Y5Im4KtfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f44b8e2-c600-4795-957a-8bccbec31431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_md-3.8.0/pt_core_news_md-3.8.0-py3-none-any.whl (42.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-md\n",
            "Successfully installed pt-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('pt_core_news_md') # Carregando o modelo pré treinado - modelo com relações entre palavras\n",
        "\n",
        "# Criação de objetos com suas informações e vetores\n",
        "palavra1 = nlp('rei')\n",
        "palavra2 = nlp('rainha')\n",
        "\n",
        "print(palavra1.similarity(palavra2)) # Cálculo de similaridade dos objetos vetorizados.\n",
        "# Valores mais próxima de  1 =  palavras similares\n",
        "# Valores mais próxima de -1 =  palavras antonimas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OBEmBz9V4aT",
        "outputId": "15aa1293-b6bf-4186-e1db-bef96b444e73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6001228094100952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 3 - Árvore Sintática"
      ],
      "metadata": {
        "id": "pl0jU6OAYRkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPFO0TpbZQD9",
        "outputId": "9c094664-add8-438b-850a-cf88a17eee70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy # Módulo para visualização de dependencias\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "frase = \"O cachorro correu no parque\"\n",
        "\n",
        "doc = nlp(frase)\n",
        "\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "rUMSCQ8qZWYE",
        "outputId": "96b25480-16b4-4f1f-ce53-3220647cad4b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"fe25471cd6f84a2cb77ac29dffb1b843-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">O</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cachorro</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">correu</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">parque</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fe25471cd6f84a2cb77ac29dffb1b843-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fe25471cd6f84a2cb77ac29dffb1b843-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fe25471cd6f84a2cb77ac29dffb1b843-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fe25471cd6f84a2cb77ac29dffb1b843-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fe25471cd6f84a2cb77ac29dffb1b843-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fe25471cd6f84a2cb77ac29dffb1b843-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fe25471cd6f84a2cb77ac29dffb1b843-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fe25471cd6f84a2cb77ac29dffb1b843-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 4 - Ontologia"
      ],
      "metadata": {
        "id": "eoSg1YqUZ9fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install owlready2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCEgtOH7Z64r",
        "outputId": "9accd321-4cb4-4548-a4f3-69ae1e260d1d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting owlready2\n",
            "  Downloading owlready2-0.47.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: owlready2\n",
            "  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for owlready2: filename=owlready2-0.47-cp311-cp311-linux_x86_64.whl size=24577496 sha256=efb7494da9f76a17ecd56e4ade0a539b495695433f5d56c984d8ee44fa782ef0\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/9a/a3/fb1ac6339caa859c8bb18d685736168b0b51d851af13d81d52\n",
            "Successfully built owlready2\n",
            "Installing collected packages: owlready2\n",
            "Successfully installed owlready2-0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from owlready2 import *\n",
        "\n",
        "onto = get_ontology(\"http://exemplo.com/minha_ontologia.owl\") # Criando uma nova ontologia\n",
        "\n",
        "with onto:\n",
        "  class Animal(Thing):pass\n",
        "  class Mamifero(Animal):pass\n",
        "  class Cachorro(Mamifero):pass\n",
        "  class Gato(Mamifero):pass\n",
        "\n",
        "onto.save(\"minha_ontologia.owl\")"
      ],
      "metadata": {
        "id": "_GtXlvAQaaWg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estudo de Caso 1 - Aplicação de Análise Semântica em um corpus"
      ],
      "metadata": {
        "id": "8G-0rricbYan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importando as bibliotecas necessárias\n",
        "import spacy\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import wordnet as wn # Banco de dados léxico - agrupa palavvras em conjutos de sinônimos"
      ],
      "metadata": {
        "id": "rOpFuSWubeRG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm') # Acessar as funcionalidades como tokenização, análise sintática e vetore de palavras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGBhxzsOdSpS",
        "outputId": "6e4041ff-1167-4266-8dd4-644f7377e67f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto do Estudo de caso\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion. Steve Jobs founded Apple in 1976.\"\n",
        "\n",
        "# 1. Análise Sintática\n",
        "doc = nlp(text)\n",
        "syntatic_data = []\n",
        "\n",
        "for token in doc:\n",
        "  syntatic_data.append({\n",
        "      \"Token\": token.text,\n",
        "      \"Pos-tag\": token.pos_,\n",
        "      \"Dependência\": token.dep_,\n",
        "      \"Cabeça da Dep\": token.head.text\n",
        "  })\n",
        "\n",
        "# Covertendo para DataFrame\n",
        "df_syntatic = pd.DataFrame(syntatic_data)\n",
        "print(\"\\n Análise Sintática:\")\n",
        "print(df_syntatic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5xt-EdQfnIs",
        "outputId": "b98564ed-420c-4be4-ef47-7237a440a992"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Análise Sintática:\n",
            "      Token Pos-tag Dependência Cabeça da Dep\n",
            "0     Apple   PROPN       nsubj       looking\n",
            "1        is     AUX         aux       looking\n",
            "2   looking    VERB        ROOT       looking\n",
            "3        at     ADP        prep       looking\n",
            "4    buying    VERB       pcomp            at\n",
            "5      U.K.   PROPN       nsubj       startup\n",
            "6   startup    VERB       ccomp        buying\n",
            "7       for     ADP        prep       startup\n",
            "8         $     SYM    quantmod       billion\n",
            "9         1     NUM    compound       billion\n",
            "10  billion     NUM        pobj           for\n",
            "11        .   PUNCT       punct       looking\n",
            "12    Steve   PROPN    compound          Jobs\n",
            "13     Jobs   PROPN       nsubj       founded\n",
            "14  founded    VERB        ROOT       founded\n",
            "15    Apple   PROPN        dobj       founded\n",
            "16       in     ADP        prep       founded\n",
            "17     1976     NUM        pobj            in\n",
            "18        .   PUNCT       punct       founded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Reconhecimento de Entidades Nomeadas (NER)\n",
        "entities_data = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  entities_data.append({\n",
        "      \"Entidade\": ent.text,\n",
        "      \"Tipo\": ent.label_\n",
        "  })\n",
        "\n",
        "# Covertendo para DataFrame\n",
        "df_entities = pd.DataFrame(entities_data)\n",
        "print(\"\\n Reconhecimento de Entidades:\")\n",
        "print(df_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLLzQheaeE0-",
        "outputId": "576d7f2c-57e2-4206-9e94-e870a12c1d2c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Reconhecimento de Entidades:\n",
            "     Entidade    Tipo\n",
            "0       Apple     ORG\n",
            "1        U.K.     GPE\n",
            "2  $1 billion   MONEY\n",
            "3  Steve Jobs  PERSON\n",
            "4       Apple     ORG\n",
            "5        1976    DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Análise Semântica com WordNet\n",
        "semantic_data = []\n",
        "\n",
        "for token in doc:\n",
        "  synsets = wn.synsets(token.text)\n",
        "  if synsets:\n",
        "    semantic_data.append({\n",
        "        \"Palavra\": token.text,\n",
        "        \"Significado\": synsets[0].definition(),\n",
        "        \"Exemplo\": synsets[0].examples()\n",
        "    })\n",
        "\n",
        "# Covertendo para DataFrame\n",
        "df_semantic = pd.DataFrame(semantic_data)\n",
        "print(\"\\n Análise Semântica:\")\n",
        "print(df_semantic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4WXeym5evSg",
        "outputId": "2af2c083-b91b-4e20-bd09-5f3ff07f804c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Reconhecimento de Entidades:\n",
            "    Palavra  ...                                            Exemplo\n",
            "0     Apple  ...                                                 []\n",
            "1        is  ...          [John is rich, This is not a good answer]\n",
            "2   looking  ...  [he went out to have a look, his look was fixe...\n",
            "3        at  ...                                                 []\n",
            "4    buying  ...  [buying and selling fill their days, shrewd pu...\n",
            "5      U.K.  ...                                                 []\n",
            "6   startup  ...    [repeated shutdowns and startups are expensive]\n",
            "7         1  ...  [he has the one but will need a two and three ...\n",
            "8   billion  ...                                                 []\n",
            "9      Jobs  ...                  [he's not in my line of business]\n",
            "10  founded  ...                    [She set up a literacy program]\n",
            "11    Apple  ...                                                 []\n",
            "12       in  ...                                                 []\n",
            "\n",
            "[13 rows x 3 columns]\n"
          ]
        }
      ]
    }
  ]
}