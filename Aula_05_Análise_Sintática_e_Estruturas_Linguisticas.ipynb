{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2XxK7paLmxe8",
        "XOZnTwa6m6Xc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinisilvanunes/P1PLN/blob/master/Aula_05_An%C3%A1lise_Sint%C3%A1tica_e_Estruturas_Linguisticas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aula 05** - Análise Sintática e Estruturas Linguísticas"
      ],
      "metadata": {
        "id": "_EpOpIm4dOaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Parte 1 - Desenvolvimento conceitual - Corporas\n",
        "2. Parte 2 - Demonstração de estruturas funcionais"
      ],
      "metadata": {
        "id": "QvGJTuLveHTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 1** - Desenvolvimento conceitual - Corporas"
      ],
      "metadata": {
        "id": "SMHstjfJetVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicio do processamento do corpus"
      ],
      "metadata": {
        "id": "dD-4LvrFPl0_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHojAO3R08ka"
      },
      "outputs": [],
      "source": [
        "# Criar uma função para fazer a abertura e leitura do arquivo\n",
        "def ler(nome_arquivo):\n",
        "  arquivo = open(nome_arquivo,'r', encoding='utf-8')\n",
        "  conteudo_arq= arquivo.read()\n",
        "  arquivo.close()\n",
        "  return conteudo_arq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# É necessário ter esse arquivo no drive ou no armazenamento da sessão, e substituir o caminho de acordo\n",
        "texto = ler('/content/drive/MyDrive/Ubirajara/2025.05 Ubirajara.txt')\n",
        "print(len(texto))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lixj5lR2D8S",
        "outputId": "bf662b1d-c0e6-4977-bd8b-e9716a301923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeira etapa - Buscador de palavras"
      ],
      "metadata": {
        "id": "RR_Qzqp9Q5vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscador(alvo,texto):\n",
        "  texto = texto.replace('\\n', ' ')\n",
        "  texto = texto.replace('\\t', ' ')\n",
        "\n",
        "  ocorrencias = []\n",
        "\n",
        "  encontrado_aqui = texto.find(alvo,0)\n",
        "  #se encontra palavra informa posição\n",
        "  #se não informa -1\n",
        "\n",
        "  while encontrado_aqui>0:\n",
        "    pos_inicial = encontrado_aqui - (40-len(alvo))\n",
        "    trecho = texto[pos_inicial: pos_inicial+80]\n",
        "\n",
        "    ocorrencias.append(trecho)\n",
        "\n",
        "    encontrado_aqui = texto.find(alvo, encontrado_aqui+1)\n",
        "    # inicia a busca a partir da posição anterior +1\n",
        "    #se encontra palavra informa posição\n",
        "    #se não informa -1\n",
        "  return ocorrencias"
      ],
      "metadata": {
        "id": "_kaMfpYx3rrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = buscador(' peito ', texto)\n",
        "\n",
        "for trecho in resultados:\n",
        "  print(trecho)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd_qwKma7XG5",
        "outputId": "a213c979-89e1-4316-ee2b-aa68b4595044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " o chefe tocantim quem recebeu no peito a ponta farpada.  Quando o corpo robusto\n",
            "nça, escrava de Jaguarê, cravou o peito do inimigo.  «Elle caiu, o guerreiro che\n",
            " labio de Jandira emudeceu; mas o peito soluçou.  A virjem conheceu que o amor d\n",
            "dos que os botões do cardo por um peito feroz, e as mãos lijeiras que tecem os f\n",
            "nte do Xingú.  As arvores que seu peito encontrava caíam lascadas.  Jurandir est\n",
            ". Os noivos cuidavam que era a do peito do tucano; mas ella sabia que era do pei\n",
            "tucano; mas ella sabia que era do peito da arára e que tinha as côres de seu gue\n",
            "s o grito de espanto sossobrou no peito dos guerreiros, e rompeu em um grito de \n",
            " do guerreiro quando se cruzam ao peito para exprimir a amizade.  Ubirajara apan\n",
            "u guerreiro.  Ubirajara cinjiu ao peito com um e outro braço, a espoza e a virje\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segunda etapa - Limpeza do corpus"
      ],
      "metadata": {
        "id": "NLe5U9T5REtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palavras = texto.split()"
      ],
      "metadata": {
        "id": "pg46Vqyk9YFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def limpar(lista):\n",
        "  lixo = '.,:;?!\"´`^~()[]{}/\\|@#$%&*¨-'\n",
        "  quase_limpo = [x.strip(lixo).lower() for x in lista]\n",
        "  return [x for x in quase_limpo if x.isalpha() or '-' not in x]"
      ],
      "metadata": {
        "id": "_bgteWy2-nqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste = \"Corro-se atrás do carro, corre se o carro for embora.\"\n",
        "word = teste.split()\n",
        "print(word)"
      ],
      "metadata": {
        "id": "02Hb_i5xRaxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cc4837-48ec-4e86-c313-1c136e94975e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Corro-se', 'atrás', 'do', 'carro,', 'corre', 'se', 'o', 'carro', 'for', 'embora.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(limpar(word))"
      ],
      "metadata": {
        "id": "3U55eKexaFPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a157d13-10e1-4af6-d5eb-40f4ff21c373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['atrás', 'do', 'carro', 'corre', 'se', 'o', 'carro', 'for', 'embora']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(palavras))\n",
        "palavras = limpar(palavras)\n",
        "print(len(palavras))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4FN7hcUAqmP",
        "outputId": "aeb18703-45ec-4936-9698-16b44e174bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37139\n",
            "36585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descrevendo os métodos utilizados na limpeza:\n",
        "* split() - transforma um texto em uma lista de palavras.\n",
        "* strip() - eliminar characteres no fim ou no começo de uma palavra.\n",
        "* isalpha - realizar um filtro eliminando numeros ou simbolos de uma lista de referência."
      ],
      "metadata": {
        "id": "OV9VyItxbsxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terceira Etapa - Quantidade de palavras"
      ],
      "metadata": {
        "id": "Ue6V2PyHfGkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Quantifica as palavras\n",
        "2. Classificação de ocorrências"
      ],
      "metadata": {
        "id": "Tw-utsV0jQC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conhecer a quantidade de palavras e vocabulário\n",
        "vocabulario = set(palavras)\n",
        "len(vocabulario)"
      ],
      "metadata": {
        "id": "DHktXErAfUXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando a riqueza textual do corpus\n",
        "riqueza = len(vocabulario)/len(palavras) # 6902 / 36585\n",
        "riqueza\n",
        "# valores próximos a 1 são ricos em palavras\n",
        "# valores próximos a 0 são pobres em palavras"
      ],
      "metadata": {
        "id": "d6WY7yAXkKed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar dicionário deste texto\n",
        "from collections import defaultdict\n",
        "def ocorrencias(lista_palavras):\n",
        "  dicionario = defaultdict(int)\n",
        "  for p in lista_palavras:\n",
        "    dicionario[p] += 1\n",
        "  return dicionario"
      ],
      "metadata": {
        "id": "mw87i08YffPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = ocorrencias(palavras)\n",
        "mf = sorted(dic.items(), key=lambda tupla: tupla[1], reverse=True)[:20]\n",
        "for palavra, n in mf:\n",
        "  print(palavra,'\\t',n)"
      ],
      "metadata": {
        "id": "2hY0Kl1knUeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "vazias = nltk.corpus.stopwords.words('portuguese')"
      ],
      "metadata": {
        "id": "MmBfqCh1pjI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequentes_plenas = [x for x in mf if x[0].lower() not in vazias]\n",
        "frequentes_plenas"
      ],
      "metadata": {
        "id": "Y_mlEaPMp0O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O que é um dicionário?\n",
        "* lista = [elemento1,elemento2,... ] - mutável\n",
        "* tupla = (elemento1,elemento2,... ) - imutável\n",
        "* dicionário = {nome_de_chave1:valor_da_chave1;nome_de_chave2:valor_da_chave2;nome_de_chave3:valor_da_chave3;... }\n",
        "\n"
      ],
      "metadata": {
        "id": "brAmYfQbfhyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 1 - POS Tagging com Spacy"
      ],
      "metadata": {
        "id": "E1FBax4Tjsk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "kaFzqzQRmES0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c581cfdd-9630-4fdd-8d4d-7c373d18d029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "frase = input(\"Insira uma frase, gramaticalmente correta: \")\n",
        "\n",
        "doc = nlp(frase)\n",
        "\n",
        "for token in doc:\n",
        "  print(f\"{token.text} -> {token.pos_}\")"
      ],
      "metadata": {
        "id": "D7vTPg-omEt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1ba3cf-2cf0-460d-f83e-29af2910be4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insira uma frase, gramaticalmente correta: Informam-me os pássaros\n",
            "Informam-me -> VERB\n",
            "os -> DET\n",
            "pássaros -> NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 2 - Pos Tagging com NLTK"
      ],
      "metadata": {
        "id": "avYY867UmFS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "8WJRUloEmXFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be6a8b0-42da-49f2-c816-b5b27f8ee9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "frase = input(\"Insira uma frase, coerente: \")\n",
        "tokens = nltk.word_tokenize(frase)\n",
        "\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "for palavra, classe in pos_tags:\n",
        "  print(f'{palavra}->{classe}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbYX01oMrPIy",
        "outputId": "20ca9a93-c741-4f56-da2d-e4d353c88a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insira uma frase, coerente: O céu é azul\n",
            "O->NNP\n",
            "céu->NN\n",
            "é->NNP\n",
            "azul->NN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 3 - Parsing de Dependência com spacy"
      ],
      "metadata": {
        "id": "LbQyCGEamXkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "frase = \"O gato preto dorme na cadeira\"\n",
        "\n",
        "doc = nlp(frase)\n",
        "\n",
        "for token in doc:\n",
        "  print(f\"{token.text} -> {token.dep_} -> {token.head.text}\")"
      ],
      "metadata": {
        "id": "_LlhveQomw4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d44846e-326b-4f4d-8473-2dafe4728271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O -> det -> gato\n",
            "gato -> ROOT -> gato\n",
            "preto -> amod -> gato\n",
            "dorme -> amod -> gato\n",
            "na -> case -> cadeira\n",
            "cadeira -> nmod -> gato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 4 - Análise de Dependência com spacy"
      ],
      "metadata": {
        "id": "2XxK7paLmxe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "frase = \"O gato preto dorme na cadeira.\"\n",
        "\n",
        "doc = nlp(frase)\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "id": "cs718JIym6ML",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "fd34e628-f502-4b4f-823a-a857490de0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"d60824f0b0264e4791e4b9d7193a0430-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">O</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">gato</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">preto</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">dorme</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">na</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">cadeira.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d60824f0b0264e4791e4b9d7193a0430-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d60824f0b0264e4791e4b9d7193a0430-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d60824f0b0264e4791e4b9d7193a0430-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d60824f0b0264e4791e4b9d7193a0430-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d60824f0b0264e4791e4b9d7193a0430-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d60824f0b0264e4791e4b9d7193a0430-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d60824f0b0264e4791e4b9d7193a0430-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d60824f0b0264e4791e4b9d7193a0430-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d60824f0b0264e4791e4b9d7193a0430-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d60824f0b0264e4791e4b9d7193a0430-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 5 - Análise de Constituência com NLTK"
      ],
      "metadata": {
        "id": "XOZnTwa6m6Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import Tree\n",
        "\n",
        "sintaxe = Tree('S', [\n",
        "    Tree('NP', [Tree('DET', ['O']), Tree('N', ['gato'])]),\n",
        "    Tree('VP', [Tree('V', ['dorme']),\n",
        "                Tree('PP', [Tree('P',['na']), Tree('NP',[Tree('N', ['cadeira'])])])])\n",
        "])\n",
        "\n",
        "sintaxe.pretty_print()"
      ],
      "metadata": {
        "id": "S8Cu0L1UnDjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f12d481-6f9e-4deb-8f64-9081c94f25ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               S                  \n",
            "      _________|____               \n",
            "     |              VP            \n",
            "     |          ____|___           \n",
            "     |         |        PP        \n",
            "     |         |     ___|_____     \n",
            "     NP        |    |         NP  \n",
            "  ___|___      |    |         |    \n",
            "DET      N     V    P         N   \n",
            " |       |     |    |         |    \n",
            " O      gato dorme  na     cadeira\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WnDVjKhvn7vj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}